{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo_LNEC.png\" alt=\"LNEC\" width=\"200\" align=\"right\"/>\n",
    "\n",
    "# ERIES - RE-SAFE PROJECT - Claudio Mazzotti (_Università di Bologna_)\n",
    "\n",
    "## Specimen for the shake table test\n",
    "\n",
    "The RC frame specimen is built at a scale of 2/3 using the Cauchy-Froude similitude law.\n",
    "\n",
    "## Shake table input motions\n",
    "\n",
    "Two different earthquake records are under consideration for the shake table test at LNEC:\n",
    "\n",
    "1. The 2009 L'Aquila earthquake (L'AQUILA-IT.AVZ.00.HNN.D.IT-2009)\n",
    "\n",
    "0. The 1976 Friuli earthquake (TOLMEZZO)\n",
    "\n",
    "## Computational environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import PPcore\\nimport RSnumba\\nimport DSP\\nimport LNEC3DST\\nfrom RSnumba import cts as RScalc\\nfrom DSP import FrequencyDomain, dBpow\\n\\n# print environment\\nPPcore.environment(globals()) '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IPython magic commands\n",
    "%matplotlib inline\n",
    "\n",
    "# Developed for Python 3.12.4\n",
    "from __future__ import annotations\n",
    "\n",
    "# Python standard library\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# 3rd party modules\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy import constants\n",
    "from scipy.signal import butter, sosfiltfilt, periodogram, resample\n",
    "from scipy.signal.windows import tukey\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pxc modules\n",
    "if (ppfolder := str(Path('..') / 'personal-packages3')) not in sys.path:\n",
    "    sys.path.append(ppfolder)\n",
    "\n",
    "\n",
    "import utilities\n",
    "import LNECSPA\n",
    "from utilities import maxabs\n",
    "from LNECSPA import LTFdb\n",
    "\n",
    "# missing imports\n",
    "\"\"\" import PPcore\n",
    "import RSnumba\n",
    "import DSP\n",
    "import LNEC3DST\n",
    "from RSnumba import cts as RScalc\n",
    "from DSP import FrequencyDomain, dBpow\n",
    "\n",
    "# print environment\n",
    "PPcore.environment(globals()) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this one\n",
    "if False:\n",
    "    ttA2 = dfA2.index\n",
    "    dtA2 = ttA2[1] - ttA2[0]\n",
    "    SpoA2 = dfA2['Spo'].to_numpy()\n",
    "\n",
    "    sos = butter(8, 40.*np.sqrt(SF), output='sos', fs=1./dtA2)\n",
    "    SpoA3 = sosfiltfilt(sos, SpoA2, padtype='even')\n",
    "\n",
    "    SpoA3 *= tukey(SpoA3.size, alpha=0.2) # 20% Tukey window\n",
    "\n",
    "    SpoA3, ttA3 = resample(SpoA3, int(ttA2.size*np.sqrt(SF)), ttA2)\n",
    "    dtA3 = ttA3[1] - ttA3[0]\n",
    "    print(dtA3) # before rounding\n",
    "\n",
    "    dtA3 = np.round(dtA3, decimals=3)\n",
    "    ttA3 = dtA3 * np.arange(ttA3.size)\n",
    "    print(ttA2[-1], ttA3[-1], dtA3, ttA3.size) # after rounding\n",
    "\n",
    "    VelA3 = FrequencyDomain.differentiate(SpoA3, dt=dtA3)\n",
    "    AccA3 = FrequencyDomain.differentiate(VelA3, dt=dtA3)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=3, sharex=True, figsize=(18,6), layout='constrained')\n",
    "    ax[-1].set_xlabel('Time (s)')\n",
    "\n",
    "    for axis, column, ts, units in zip(ax, ('Spo', 'Vel', 'Acc'), (SpoA3, VelA3, AccA3), ('cm', 'cm/s', 'cm/s²')):\n",
    "        axis.plot(dfA2[column], label=f'Scalato (peak={maxabs(dfA2[column]):.1f}{units})')\n",
    "        axis.plot(ttA3, ts, label=f'Processed (peak={maxabs(ts):.1f}{units})')\n",
    "        axis.set_ylabel(f'{column} ({units})')\n",
    "        axis.legend(loc='upper right')\n",
    "        axis.grid(visible=True)\n",
    "\n",
    "    ## Export data\n",
    "    fA3 = pd.DataFrame(data=(SpoA3, VelA3, AccA3), index=('Spo (cm)', 'Vel (cm/s)', 'Acc (cm/s²)'), columns=ttA3).T\n",
    "    dfA3.index.name = 'Time (s)'\n",
    "    dfA3RS = pd.DataFrame(data=rsa, index=TT, columns=('Acc (cm/s²)',))\n",
    "    dfA3RS.index.name = 'Time (s)'\n",
    "\n",
    "    with pd.ExcelWriter(\"L'AQUILA-IT.AVZ.00.HNN.D.IT-2009_LNEC3D.xlsx\") as writer:\n",
    "        dfA3.to_excel(writer, sheet_name='Time series', index=True)\n",
    "        dfA3RS.to_excel(writer, sheet_name='Response spectrum', index=True)\n",
    "\n",
    "    # LTF file\n",
    "    ltfA = LTFdb()\n",
    "    ltfA.update(AQTD=['AQTD'],\n",
    "                stage=[\"L'AQUILA-IT.AVZ.00.HNN.D.IT-2009 seismic record, scale factor 2/3, Cauchy+Froude similitude law\"],\n",
    "                obs=['ERIES RE-Safe project'],\n",
    "                date=[str(datetime.datetime.now())],\n",
    "                t0=np.repeat(ltfA.t0, 3),\n",
    "                dt=np.repeat(ltfA.dt*0.005, 3),\n",
    "                dataformat=np.repeat(ltfA.dataformat, 3),\n",
    "                IDstring=ltfA.IDstring*3,\n",
    "                scalefactor=np.repeat(ltfA.scalefactor, 3),\n",
    "                offset=np.repeat(ltfA.offset, 3),\n",
    "                data=np.vstack((SpoA3*10., VelA3, AccA3/100./constants.g)), # acceleration is in G's\n",
    "                names=['DispT', 'VelT', 'AccT'],\n",
    "                units=['mm', 'cm/s', 'g'],  # attention to units (Not SI)\n",
    "                types=['Displacement', 'Velocity', 'Acceleration'],\n",
    "                info=[f'PGD={maxabs(SpoA3*10.):.0f}mm', f'PGV={maxabs(VelA3):.2f}cm/s', f'PGA={maxabs(AccA3/100./constants.g):.3f}g'],\n",
    "                )\n",
    "    ltfA.write('LAquilaReducedScale.ltf')\n",
    "\n",
    "    # LNEC3D shake table target motion file\n",
    "    tgtA = LTFdb()\n",
    "    tgtA.update(AQTD=['AQTD'],\n",
    "                stage=[\"L'AQUILA-IT.AVZ.00.HNN.D.IT-2009 seismic record, scale factor 2/3, Cauchy+Froude similitude law\"],\n",
    "                obs=['ERIES RE-Safe project'],\n",
    "                date=[str(datetime.datetime.now())],\n",
    "                t0=np.repeat(tgtA.t0, 6),\n",
    "                dt=np.repeat(tgtA.dt*0.005, 6),\n",
    "                dataformat=np.repeat(tgtA.dataformat, 6),\n",
    "                IDstring=tgtA.IDstring*6,\n",
    "                scalefactor=np.repeat(tgtA.scalefactor, 6),\n",
    "                offset=np.repeat(tgtA.offset, 6),\n",
    "                data=np.vstack((SpoA3*10., SpoA3*0., SpoA3*0., AccA3/100./constants.g, AccA3*0., AccA3*0.)),\n",
    "                names=['DispT', 'DispL', 'DispV', 'AccT', 'AccL', 'AccV'],\n",
    "                units=['mm']*3 + ['g']*3,\n",
    "                types=['Displacement']*3 + ['Acceleration']*3,\n",
    "                info=tgtA.info*6,\n",
    "                )\n",
    "    tgtA.write('LAquilaReducedScale.tgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: C:\\Users\\afons\\OneDrive - Universidade de Lisboa\\Controlo de Plataforma Sismica\\LNEC_Adapta_Driver\\2024_ERIES_RE-Safe\\Targets\\LAquilaReducedScale.tgt\n",
      "AQTD: ['AQTD']\n",
      "Stage: [\"L'AQUILA-IT.AVZ.00.HNN.D.IT-2009 seismic record, scale factor 2/3, Cauchy+Froude similitude law\"]\n",
      "Obs: ['ERIES RE-Safe project']\n",
      "Date: ['2024-07-19 12:18:26.272293']\n",
      "Signals: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tgtA = LTFdb()\n",
    "tgtA.read(r'C:\\Users\\afons\\OneDrive - Universidade de Lisboa\\Controlo de Plataforma Sismica\\LNEC_Adapta_Driver\\2024_ERIES_RE-Safe\\Targets\\LAquilaReducedScale.tgt')\n",
    "print(tgtA)\n",
    "print()\n",
    "#tgtA.print_metadata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 8982 samples and 3 columns to 'tgtA_SI_time_disp_acc.txt'.\n"
     ]
    }
   ],
   "source": [
    "# AI generated code for file format conversion to .txt and to SI units\n",
    "\n",
    "import numpy as np\n",
    "from scipy.constants import g\n",
    "\n",
    "# Assuming tgtA is already loaded via LTFdb.read\n",
    "\n",
    "# 1. Identify channel indices\n",
    "disp_inds = [i for i, unit in enumerate(tgtA.units) if unit.lower() in ('mm', 'm')]\n",
    "acc_inds  = [i for i, typ  in enumerate(tgtA.types) if typ.lower() == 'acceleration']\n",
    "\n",
    "# 2. Build time vector\n",
    "dt     = float(tgtA.dt[0])\n",
    "n_pts  = tgtA.data.shape[1]\n",
    "time_s = np.arange(n_pts) * dt\n",
    "\n",
    "# 3. Convert to SI\n",
    "# Displacement (to meters)\n",
    "disp_si = tgtA.data[disp_inds].astype(float)\n",
    "for idx, ch in enumerate(disp_inds):\n",
    "    if tgtA.units[ch].lower() == 'mm':\n",
    "        disp_si[idx] *= 1e-3\n",
    "\n",
    "# Acceleration (to m/s^2)\n",
    "acc_si = tgtA.data[acc_inds].astype(float)\n",
    "for idx, ch in enumerate(acc_inds):\n",
    "    if tgtA.units[ch].lower() == 'g':\n",
    "        acc_si[idx] *= g\n",
    "\n",
    "# 4. Stack columns: time | displacements | accelerations\n",
    "out_arr = np.vstack((time_s, disp_si, acc_si)).T  # shape (n_pts, 1 + n_disp + n_acc)\n",
    "\n",
    "# 5. Remove columns that are entirely zero\n",
    "mask = ~np.all(np.isclose(out_arr, 0.0), axis=0)\n",
    "out_arr = out_arr[:, mask]\n",
    "\n",
    "# 6. Prepare headers aligned with filtered columns\n",
    "header_cols = ['time_s'] + \\\n",
    "    [f\"{tgtA.names[i]}_m\" for i in disp_inds] + \\\n",
    "    [f\"{tgtA.names[i]}_m_per_s2\" for i in acc_inds]\n",
    "header_cols = [h for h, m in zip(header_cols, mask) if m]\n",
    "\n",
    "# 7. Export with fixed-width columns and aligned headers\n",
    "width = 15\n",
    "fmt = ['%15.6e'] * len(header_cols)\n",
    "\n",
    "# Build header line with each column name centered\n",
    "header_line = ''.join(h.center(width) for h in header_cols)\n",
    "\n",
    "txt_filename = 'tgtA_SI_time_disp_acc.txt'\n",
    "with open(txt_filename, 'w') as f:\n",
    "    f.write(header_line + '\\n')\n",
    "    np.savetxt(f, out_arr, fmt=fmt)\n",
    "\n",
    "print(f\"Exported {out_arr.shape[0]} samples and {out_arr.shape[1]} columns to '{txt_filename}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48b24ca315487c062b8b23042ff6a0ae2476b1452409cf5c7326ae21be24bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
